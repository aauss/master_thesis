Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@inproceedings{Chen2018,
abstract = {Multilingual Word Embeddings (MWEs) represent words from multiple languages in a single distributional vector space. Unsupervised MWE (UMWE) methods acquire multilingual embeddings without cross-lingual supervision, which is a significant advantage over traditional supervised approaches and opens many new possibilities for low-resource languages. Prior art for learning UMWEs, however, merely relies on a number of independently trained Unsupervised Bilingual Word Embeddings (UBWEs) to obtain multilingual embeddings. These methods fail to leverage the interdependencies that exist among many languages. To address this shortcoming, we propose a fully unsupervised framework for learning MWEs that directly exploits the relations between all language pairs. Our model substantially outperforms previous approaches in the experiments on multilingual word translation and cross-lingual word similarity. In addition, our model even beats supervised approaches trained with cross-lingual resources.},
archivePrefix = {arXiv},
arxivId = {1808.08933},
author = {Chen, Xilun and Cardie, Claire},
booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
eprint = {1808.08933},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Chen, Cardie - 2018 - Unsupervised Multilingual Word Embeddings.pdf:pdf},
month = {aug},
pages = {261----270},
publisher = {Association for Computational Linguistics},
title = {{Unsupervised Multilingual Word Embeddings}},
url = {https://www.aclweb.org/anthology/D18-1024},
year = {2018}
}
@article{Faensen2004,
abstract = {In Germany, since 2001, more than 50 infectious diseases or pathogens have been notifiable under the Infektionsschutzgesetz. Case based data are compiled at the Robert Koch Institute in a central database. By October 2003, this database held 860,000 case records and is currently growing by 300,000 cases per year.},
author = {Faensen, D and Krause, G},
doi = {10.2807/esw.08.22.02477-en},
issn = {9999-1233},
journal = {Weekly releases (1997–2007)},
month = {may},
number = {22},
pages = {2477},
publisher = {European Centre for Disease Prevention and Control},
title = {{SurvStat@RKI – a web-based solution to query surveillance data in Germany}},
url = {http://www.eurosurveillance.org/content/10.2807/esw.08.22.02477-en},
volume = {8},
year = {2004}
}
@misc{WHOepi,
author = {WHO},
booktitle = {WHO},
keywords = {data,epidemiology [subject],health statistics,health systems [subject],statistics [subject],surveillance},
publisher = {World Health Organization},
title = {{Epidemiology}},
url = {https://www.who.int/topics/epidemiology/en/},
urldate = {2019-03-05},
year = {2014}
}
@article{Rish2001,
author = {Rish, Irina},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Rish - 2001 - An Empirical Study of the Na{\"{i}}ve Bayes Classifier.pdf:pdf},
journal = {IJCAI 2001 Work Empir Methods Artif Intell},
title = {{An Empirical Study of the Na{\"{i}}ve Bayes Classifier}},
volume = {3},
year = {2001}
}
@article{Kingma2014,
abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
archivePrefix = {arXiv},
arxivId = {1412.6980},
author = {Kingma, Diederik P. and Ba, Jimmy},
eprint = {1412.6980},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Kingma, Ba - 2014 - Adam A Method for Stochastic Optimization.pdf:pdf},
journal = {arXiv},
month = {dec},
title = {{Adam: A Method for Stochastic Optimization}},
url = {http://arxiv.org/abs/1412.6980},
year = {2014}
}
@incollection{Mohr2010,
author = {Mohr, Oliver and Velasco, Edward and Fell, Gerhard and Burckhardt, Florian and Poggensee, Gabriele and Eckmanns, Tim},
booktitle = {Bundesgesundheitsblatt - Gesundheitsforschung - Gesundheitsschutz},
doi = {10.1007/s00103-010-1122-z},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Mohr et al. - 2010 - Die telefonische infektionsepidemiologische Bund-L{\"{a}}nder-Lagekonferenz in Deutschland - Eine Zwischenbilanz nach dr.pdf:pdf},
publisher = {Robert Koch-Institut, Infektionsepidemiologie},
title = {{Die telefonische infektionsepidemiologische Bund-L{\"{a}}nder-Lagekonferenz in Deutschland - Eine Zwischenbilanz nach drei Quartalen 2009}},
url = {https://edoc.rki.de/bitstream/handle/176904/916/25RYrvOTxkGp6.pdf?sequence=1{\&}isAllowed=y},
year = {2010}
}
@inproceedings{Devlin2018,
abstract = {"We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\{}$\backslash${\%}{\}} (4.6{\{}$\backslash${\%}{\}} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
archivePrefix = {arXiv},
arxivId = {1810.04805},
author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
booktitle = {Proceedings of the 2019 Conference of the North {\{}A{\}}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
eprint = {1810.04805},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Devlin et al. - 2018 - BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf:pdf},
month = {oct},
pages = {4171----4186},
publisher = {Association for Computational Linguistics},
title = {{BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}},
url = {https://www.aclweb.org/anthology/N19-1423},
year = {2019}
}
@article{Lodhi2002,
author = {Lodhi, Huma and Saunders, Craig and Shawe-Taylor, John and Cristianini, Nello and Watkins, Chris},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Lodhi et al. - 2002 - Text Classification using String Kernels.pdf:pdf},
issn = {ISSN 1533-7928},
journal = {Journal of Machine Learning Research},
number = {Feb},
pages = {419--444},
title = {{Text Classification using String Kernels}},
url = {http://www.jmlr.org/papers/v2/lodhi02a.html},
volume = {2},
year = {2002}
}
@misc{word2vec,
author = {{Code Google}},
title = {{Google Code Archive - Long-term storage for Google Code Project Hosting.}},
url = {https://code.google.com/archive/p/word2vec/},
urldate = {2019-03-25},
year = {2013}
}
@book{Basciepi,
author = {Bonita, R. and Beaglehole, R. and Kjellstr{\"{o}}m, T.},
edition = {2.},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Bonita, Beaglehole, Kjellstr{\"{o}}m - 2006 - Basic epidemiology.pdf:pdf},
isbn = {92 4 154707 3},
publisher = {WHO},
title = {{Basic epidemiology}},
url = {https://apps.who.int/iris/bitstream/handle/10665/43541/9241547073{\_}eng.pdf;jsessionid=BC713A01D9413B55C5085B2083544DD7?sequence=1},
year = {2006}
}
@article{Stephen2016,
abstract = {Objective Foodborne illnesses in Australia, including salmonellosis, are estimated to cost over {\$}A1.25 billion annually. The weather has been identified as being influential on salmonellosis incidence, as cases increase during summer, however time series modelling of salmonellosis is challenging because outbreaks cause strong autocorrelation. This study assesses whether switching models is an improved method of estimating weather{\{}\backslashtextendash{\}}salmonellosis associations.Design We analysed weather and salmonellosis in South-East Queensland between 2004 and 2013 using 2 common regression models and a switching model, each with 21-day lags for temperature and precipitation.Results The switching model best fit the data, as judged by its substantial improvement in deviance information criterion over the regression models, less autocorrelated residuals and control of seasonality. The switching model estimated a 5{\{}\backslashtextdegree{\}}C increase in mean temperature and 10 mm precipitation were associated with increases in salmonellosis cases of 45.4{\%} (95{\%} CrI 40.4{\%}, 50.5{\%}) and 24.1{\%} (95{\%} CrI 17.0{\%}, 31.6{\%}), respectively.Conclusions Switching models improve on traditional time series models in quantifying weather{\{}\backslashtextendash{\}}salmonellosis associations. A better understanding of how temperature and precipitation influence salmonellosis may identify where interventions can be made to lower the health and economic costs of salmonellosis.},
author = {Stephen, Dimity Maree and Barnett, Adrian Gerard},
doi = {10.1136/bmjopen-2015-010204},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Stephen, Barnett - 2016 - Effect of temperature and precipitation on salmonellosis cases in South-East Queensland, Australia an obser(3).pdf:pdf},
issn = {2044-6055},
journal = {BMJ Open},
number = {2},
publisher = {British Medical Journal Publishing Group},
title = {{Effect of temperature and precipitation on salmonellosis cases in South-East Queensland, Australia: an observational study}},
url = {https://bmjopen.bmj.com/content/6/2/e010204},
volume = {6},
year = {2016}
}
@article{Linge2009,
abstract = {In order to gather a comprehensive picture of potential epidemic threats, public health authorities increasingly rely on systems that perform epidemic intelligence (EI). EI makes use of information that originates from official sources such as national public health surveillance systems as well as from informal sources such as electronic media and web-based information tools.},
author = {Linge, J P and Steinberger, R and Weber, T P and Yangarber, R and van der Goot, E and Khudhairy, D H Al and Stilianakis, N I},
doi = {10.2807/ese.14.13.19162-en},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Linge et al. - 2009 - Internet surveillance systems for early alerting of health threats.pdf:pdf},
issn = {1560-7917},
journal = {Eurosurveillance},
month = {apr},
number = {13},
pages = {19162},
publisher = {European Centre for Disease Prevention and Control},
title = {{Internet surveillance systems for early alerting of health threats}},
url = {https://www.eurosurveillance.org/content/10.2807/ese.14.13.19162-en},
volume = {14},
year = {2009}
}
@inproceedings{Kohlschutter2010,
address = {New York, New York, USA},
author = {Kohlsch{\"{u}}tter, Christian and Fankhauser, Peter and Nejdl, Wolfgang},
booktitle = {Proceedings of the third ACM international conference on Web search and data mining - WSDM '10},
doi = {10.1145/1718487.1718542},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Kohlsch{\"{u}}tter, Fankhauser, Nejdl - 2010 - Boilerplate detection using shallow text features.pdf:pdf},
isbn = {9781605588896},
keywords = {boilerplate removal,full-text extraction,template detection,text cleaning,web document modeling},
pages = {441},
publisher = {ACM Press},
title = {{Boilerplate detection using shallow text features}},
url = {http://portal.acm.org/citation.cfm?doid=1718487.1718542},
year = {2010}
}
@book{Mitchell1997,
abstract = {Mitchell covers the field of machine learning, the study of algorithms that allow computer programs to automatically improve through experience and that automatically infer general laws from specific data. 1. Introduction -- 2. Concept Learning and the General-to-Specific Ordering -- 3. Decision Tree Learning -- 4. Artificial Neural Networks -- 5. Evaluating Hypotheses -- 6. Bayesian Learning -- 7. Computational Learning Theory -- 8. Instance-Based Learning -- 9. Genetic Algorithms -- 10. Learning Sets of Rules -- 11. Analytical Learning -- 12. Combining Inductive and Analytical Learning -- 13. Reinforcement Learning.},
author = {Mitchell, Tom M.},
isbn = {0070428077},
pages = {414},
publisher = {McGraw-Hill},
title = {{Machine Learning}},
url = {http://www.cs.cmu.edu/{~}tom/mlbook.html},
year = {1997}
}
@article{Bengio2003,
author = {Bengio, Yoshua and Ducharme, R{\'{e}}jean and Vincent, Pascal and Jauvin, Christian},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Bengio et al. - 2003 - A Neural Probabilistic Language Model.pdf:pdf},
issn = {ISSN 1533-7928},
journal = {Journal of Machine Learning Research},
number = {Feb},
pages = {1137--1155},
title = {{A Neural Probabilistic Language Model}},
url = {http://www.jmlr.org/papers/v3/bengio03a.html},
volume = {3},
year = {2003}
}
@article{Le2014,
abstract = {Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, "powerful," "strong" and "Paris" are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.},
archivePrefix = {arXiv},
arxivId = {1405.4053},
author = {Le, Quoc V. and Mikolov, Tomas},
eprint = {1405.4053},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Le, Mikolov - 2014 - Distributed Representations of Sentences and Documents.pdf:pdf},
month = {may},
title = {{Distributed Representations of Sentences and Documents}},
url = {http://arxiv.org/abs/1405.4053},
year = {2014}
}
@inproceedings{Garcia2009,
author = {Garc{\'{i}}a, V and {A. Mollineda}, R and S{\'{a}}nchez, Jos{\'{e}}},
booktitle = {4th Iberian Conference},
doi = {10.1007/978-3-642-02172-5_57},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Garc{\'{i}}a, A. Mollineda, S{\'{a}}nchez - 2009 - Index of Balanced Accuracy A Performance Measure for Skewed Class Distributions.pdf:pdf},
pages = {441--448},
title = {{Index of Balanced Accuracy: A Performance Measure for Skewed Class Distributions}},
volume = {5524},
year = {2009}
}
@article{Kiss2006,
abstract = {In this article, we present a language-independent, unsupervised approach to sentence boundary detection. It is based on the assumption that a large number of ambiguities in the determination of sentence boundaries can be eliminated once abbreviations have been identified. Instead of relying on orthographic clues, the proposed system is able to detect abbreviations with high accuracy using three criteria that only require information about the candidate type itself and are independent of context: Abbreviations can be defined as a very tight collocation consisting of a truncated word and a final period, abbreviations are usually short, and abbreviations sometimes contain internal periods. We also show the potential of collocational evidence for two other important subtasks of sentence boundary disambiguation, namely, the detection of initials and ordinal numbers. The proposed system has been tested extensively on eleven different languages and on different text genres. It achieves good results without any ...},
author = {Kiss, Tibor and Strunk, Jan},
doi = {10.1162/coli.2006.32.4.485},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Kiss, Strunk - 2006 - Unsupervised Multilingual Sentence Boundary Detection.pdf:pdf},
issn = {0891-2017},
journal = {Computational Linguistics},
month = {dec},
number = {4},
pages = {485--525},
publisher = {MIT Press 238 Main St., Suite 500, Cambridge, MA 02142-1046USA journals-info@mit.edu},
title = {{Unsupervised Multilingual Sentence Boundary Detection}},
url = {http://www.mitpressjournals.org/doi/10.1162/coli.2006.32.4.485},
volume = {32},
year = {2006}
}
@book{Russell2009,
address = {Upper Saddle River, NJ, USA},
author = {Russell, Stuart and Norvig, Peter},
edition = {3rd},
isbn = {0136042597, 9780136042594},
publisher = {Prentice Hall Press},
title = {{Artificial Intelligence: A Modern Approach}},
year = {2009}
}
@article{Jimeno2007,
abstract = {In recent years, the recognition of semantic types from the biomedical scientific literature has been focused on named entities like protein and gene names (PGNs) and gene ontology terms (GO terms). Other semantic types like diseases have not received the same level of attention. Different solutions have been proposed to identify disease named entities in the scientific literature. While matching the terminology with language patterns suffers from low recall (e.g., Whatizit) other solutions make use of morpho-syntactic features to better cover the full scope of terminological variability (e.g., MetaMap). Currently, MetaMap that is provided from the National Library of Medicine (NLM) is the state of the art solution for the annotation of concepts from UMLS (Unified Medical Language System) in the literature. Nonetheless, its performance has not yet been assessed on an annotated corpus. In addition, little effort has been invested so far to generate an annotated dataset that links disease entities in text to disease entries in a database, thesaurus or ontology and that could serve as a gold standard to benchmark text mining solutions. As part of our research work, we have taken a corpus that has been delivered in the past for the identification of associations of genes to diseases based on the UMLS Metathesaurus and we have reprocessed and re-annotated the corpus. We have gathered annotations for disease entities from two curators, analyzed their disagreement (0.51 in the kappa-statistic) and composed a single annotated corpus for public use. Thereafter, three solutions for disease named entity recognition including MetaMap have been applied to the corpus to automatically annotate it with UMLS Metathesaurus concepts. The resulting annotations have been benchmarked to compare their performance. The annotated corpus is publicly available at ftp://ftp.ebi.ac.uk/pub/software/textmining/corpora/diseases and can serve as a benchmark to other systems. In addition, we found that dictionary look-up already provides competitive results indicating that the use of disease terminology is highly standardized throughout the terminologies and the literature. MetaMap generates precise results at the expense of insufficient recall while our statistical method obtains better recall at a lower precision rate. Even better results in terms of precision are achieved by combining at least two of the three methods leading, but this approach again lowers recall. Altogether, our analysis gives a better understanding of the complexity of disease annotations in the literature. MetaMap and the dictionary based approach are available through the Whatizit web service infrastructure (Rebholz-Schuhmann D, Arregui M, Gaudan S, Kirsch H, Jimeno A: Text processing through Web services: Calling Whatizit. Bioinformatics 2008, 24:296-298).},
author = {Jimeno, Antonio and Jimenez-Ruiz, Ernesto and Lee, Vivian and Gaudan, Sylvain and Berlanga, Rafael and Rebholz-Schuhmann, Dietrich},
doi = {10.1186/1471-2105-9-S3-S3},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Jimeno et al. - 2008 - Assessment of disease named entity recognition on a corpus of annotated sentences.pdf:pdf},
issn = {1471-2105},
journal = {BMC Bioinformatics},
keywords = {Algorithms,Bioinformatics,Combinatorial Libraries,Computational Biology/Bioinformatics,Computer Appl. in Life Sciences,Microarrays},
month = {apr},
number = {3},
pages = {S3},
publisher = {BioMed Central},
title = {{Assessment of disease named entity recognition on a corpus of annotated sentences}},
url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-9-S3-S3},
volume = {9},
year = {2008}
}
@incollection{Kakas2011,
address = {Boston, MA},
author = {Kakas, Antonis C and Cohn, David and Dasgupta, Sanjoy and Barto, Andrew G and Carpenter, Gail A and Grossberg, Stephen and Webb, Geoffrey I and Dorigo, Marco and Birattari, Mauro and Toivonen, Hannu and Timmis, Jon and Branke, J{\"{u}}rgen and Toivonen, Hannu and Strehl, Alexander L and Drummond, Chris and Coates, Adam and Abbeel, Pieter and Ng, Andrew Y and Zheng, Fei and Webb, Geoffrey I and Tadepalli, Prasad},
booktitle = {Encyclopedia of Machine Learning},
doi = {10.1007/978-0-387-30164-8_6},
pages = {10--14},
publisher = {Springer US},
title = {{Active Learning}},
url = {http://www.springerlink.com/index/10.1007/978-0-387-30164-8{\_}6},
year = {2011}
}
@inproceedings{Rennie2003,
address = {Washington, DC, USA},
author = {Rennie, Jason D. M. and Shih, Lawrence and Teevan, Jaime and Karger, David R.},
booktitle = {In Proceedings of the Twentieth International Conference on Machine Learning},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Rennie et al. - 2003 - Tackling the Poor Assumptions of Naive Bayes Text Classifiers.pdf:pdf},
pages = {616--623},
publisher = {AAAI Press},
title = {{Tackling the Poor Assumptions of Naive Bayes Text Classifiers}},
url = {http://citeseerx.ist.psu.edu/viewdoc/citations?doi=10.1.1.13.8572},
year = {2003}
}
@article{Taylor2015,
abstract = {Background and Methods Cholera remains a significant threat to global public health with an estimated 100,000 deaths per year. Water, sanitation and hygiene (WASH) interventions are frequently employed to control outbreaks though evidence regarding their effectiveness is often missing. This paper presents a systematic literature review investigating the function, use and impact of WASH interventions implemented to control cholera. Results The review yielded eighteen studies and of the five studies reporting on health impact, four reported outcomes associated with water treatment at the point of use, and one with the provision of improved water and sanitation infrastructure. Furthermore, whilst the reporting of function and use of interventions has become more common in recent publications, the quality of studies remains low. The majority of papers ({\textgreater}60{\%}) described water quality interventions, with those at the water source focussing on ineffective chlorination of wells, and the remaining being applied at the point of use. Interventions such as filtration, solar disinfection and distribution of chlorine products were implemented but their limitations regarding the need for adherence and correct use were not fully considered. Hand washing and hygiene interventions address several transmission routes but only 22{\%} of the studies attempted to evaluate them and mainly focussed on improving knowledge and uptake of messages but not necessarily translating this into safer practices. The use and maintenance of safe water storage containers was only evaluated once, under-estimating the considerable potential for contamination between collection and use. This problem was confirmed in another study evaluating methods of container disinfection. One study investigated uptake of household disinfection kits which were accepted by the target population. A single study in an endemic setting compared a combination of interventions to improve water and sanitation infrastructure, and the resulting reductions in cholera incidence. Discussion and Recommendations This review highlights a focus on particular routes of transmission, and the limited number of interventions tested during outbreaks. There is a distinct gap in knowledge of which interventions are most appropriate for a given context and as such a clear need for more robust impact studies evaluating a wider array of WASH interventions, in order to ensure effective cholera control and the best use of limited resources.},
author = {Taylor, Dawn L. and Kahawita, Tanya M. and Cairncross, Sandy and Ensink, Jeroen H. J.},
doi = {10.1371/journal.pone.0135676},
editor = {Bhutta, Zulfiqar A.},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Taylor et al. - 2015 - The Impact of Water, Sanitation and Hygiene Interventions to Control Cholera A Systematic Review.pdf:pdf},
issn = {1932-6203},
journal = {PLOS ONE},
month = {aug},
number = {8},
pages = {e0135676},
publisher = {Public Library of Science},
title = {{The Impact of Water, Sanitation and Hygiene Interventions to Control Cholera: A Systematic Review}},
url = {https://dx.plos.org/10.1371/journal.pone.0135676},
volume = {10},
year = {2015}
}
@article{Lopez2013,
abstract = {Training classifiers with datasets which suffer of imbalanced class distributions is an important problem in data mining. This issue occurs when the number of examples representing the class of interest is much lower than the ones of the other classes. Its presence in many real-world applications has brought along a growth of attention from researchers. We shortly review the many issues in machine learning and applications of this problem, by introducing the characteristics of the imbalanced dataset scenario in classification, presenting the specific metrics for evaluating performance in class imbalanced learning and enumerating the proposed solutions. In particular, we will describe preprocessing, cost-sensitive learning and ensemble techniques, carrying out an experimental study to contrast these approaches in an intra and inter-family comparison. We will carry out a thorough discussion on the main issues related to using data intrinsic characteristics in this classification problem. This will help to improve the current models with respect to: the presence of small disjuncts, the lack of density in the training data, the overlapping between classes, the identification of noisy data, the significance of the borderline instances, and the dataset shift between the training and the test distributions. Finally, we introduce several approaches and recommendations to address these problems in conjunction with imbalanced data, and we will show some experimental examples on the behavior of the learning algorithms on data with such intrinsic characteristics.},
author = {L{\'{o}}pez, Victoria and Fern{\'{a}}ndez, Alberto and Garc{\'{i}}a, Salvador and Palade, Vasile and Herrera, Francisco},
doi = {10.1016/J.INS.2013.07.007},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/L{\'{o}}pez et al. - 2013 - An insight into classification with imbalanced data Empirical results and current trends on using data intrinsic.pdf:pdf},
issn = {0020-0255},
journal = {Information Sciences},
month = {nov},
pages = {113--141},
publisher = {Elsevier},
title = {{An insight into classification with imbalanced data: Empirical results and current trends on using data intrinsic characteristics}},
url = {https://www.sciencedirect.com/science/article/pii/S0020025513005124},
volume = {250},
year = {2013}
}
@article{Wu2018,
archivePrefix = {arXiv},
arxivId = {1811.01713},
author = {Wu, Lingfei and Yen, Ian En-Hsu and Xu, Kun and Xu, Fangli and Balakrishnan, Avinash and Chen, Pin-Yu and Ravikumar, Pradeep and Witbrock, Michael J},
eprint = {1811.01713},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Wu et al. - 2018 - Word Mover's Embedding From Word2Vec to Document Embedding.pdf:pdf},
journal = {CoRR},
title = {{Word Mover's Embedding: From Word2Vec to Document Embedding}},
url = {http://arxiv.org/abs/1811.01713},
volume = {abs/1811.0},
year = {2018}
}
@book{bird2009natural,
author = {Bird, Steven and Klein, Ewan and Loper, Edward},
edition = {1st},
isbn = {0596516495, 9780596516499},
publisher = {O'Reilly Media, Inc.},
title = {{Natural Language Processing with Python}},
year = {2009}
}
@inproceedings{Conneau2016,
address = {Valencia, Spain},
author = {Conneau, Alexis and Schwenk, Holger and Barrault, Lo{\"{i}}c and Lecun, Yann},
booktitle = {Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Conneau et al. - 2017 - Very Deep Convolutional Networks for Text Classification.pdf:pdf},
pages = {1107--1116},
publisher = {Association for Computational Linguistics},
title = {{Very Deep Convolutional Networks for Text Classification}},
url = {https://www.aclweb.org/anthology/papers/E/E17/E17-1104/},
year = {2017}
}
@book{Bengfort2018,
author = {Bengfort, Benjaming and Ojeda, Tony and Bilbro, Rebecca},
isbn = {9781491963043},
pages = {332},
publisher = {O'Reilly Media, Inc.},
title = {{Applied Text Analysis with Python: Enabling Language-Aware Data Products with Machine Learning}},
year = {2018}
}
@inproceedings{Muller2015,
address = {Lisbon, Portugal},
author = {M{\"{u}}ller, Thomas and Cotterell, Ryan and Fraser, Alexander and Sch{\"{u}}tze, Hinrich},
booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
doi = {10.18653/v1/D15-1272},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/M{\"{u}}ller et al. - 2015 - Joint Lemmatization and Morphological Tagging with Lemming.pdf:pdf},
pages = {2268--2274},
publisher = {Association for Computational Linguistics},
title = {{Joint Lemmatization and Morphological Tagging with Lemming}},
url = {http://aclweb.org/anthology/D15-1272},
year = {2015}
}
@book{Brid2009,
author = {Brid, Steven and Klein, Ewan and Loper, Edward},
publisher = {O'Reilly Media, Inc.},
title = {{Natural language processing with Python: analyzing text with the natural language toolkit}},
year = {2009}
}
@article{Lemaitre2017,
abstract = {Imbalanced-learn is an open-source python toolbox aiming at providing a wide range of methods to cope with the problem of imbalanced dataset frequently encountered in machine learning and pattern recognition. The implemented state-of-the-art methods can be categorized into 4 groups: (i) under-sampling, (ii) over-sampling, (iii) combination of over- and under-sampling, and (iv) ensemble learning methods. The proposed toolbox only depends on numpy, scipy, and scikit-learn and is distributed under MIT license. Furthermore, it is fully compatible with scikit-learn and is part of the scikit-learn-contrib supported project. Documentation, unit tests as well as integration tests are provided to ease usage and contribution. The toolbox is publicly available in GitHub: https://github.com/scikit-learn-contrib/imbalanced-learn.},
archivePrefix = {arXiv},
arxivId = {1609.06570},
author = {Lemaitre, Guillaume and Nogueira, Fernando and Aridas, Christos K.},
eprint = {1609.06570},
journal = {Journal of Machine Learning Research},
month = {sep},
number = {17},
pages = {1--5},
title = {{Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning}},
url = {http://jmlr.org/papers/v18/16-365},
volume = {18},
year = {2017}
}
@article{Howard2018,
abstract = {Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24{\%} on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100x more data. We open-source our pretrained models and code.},
archivePrefix = {arXiv},
arxivId = {1801.06146},
author = {Howard, Jeremy and Ruder, Sebastian},
doi = {arXiv:1801.06146v3},
eprint = {1801.06146},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Howard, Ruder - 2018 - Universal Language Model Fine-tuning for Text Classification.pdf:pdf},
isbn = {2333-0384},
issn = {23330384},
month = {jan},
pmid = {24482784},
title = {{Universal Language Model Fine-tuning for Text Classification}},
url = {http://arxiv.org/abs/1801.06146},
year = {2018}
}
@inproceedings{Liu2018,
author = {Liu, Chundi and Zhao, Shunan and Volkovs, Maksims},
booktitle = {arXiv},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Liu, Zhao, Volkovs - 2018 - Unsupervised Document Embedding With CNNs.pdf:pdf},
title = {{Unsupervised Document Embedding With CNNs.}},
year = {2018}
}
@inproceedings{Peters2018,
abstract = {We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.},
address = {New Orleans, Louisiana},
archivePrefix = {arXiv},
arxivId = {1802.05365},
author = {Peters, Matthew E. and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
booktitle = {Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
eprint = {1802.05365},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Peters et al. - 2018 - Deep contextualized word representations.pdf:pdf},
month = {feb},
pages = {2227----2237},
publisher = {Association for Computational Linguistics},
title = {{Deep contextualized word representations}},
url = {https://www.aclweb.org/anthology/N18-1202},
year = {2018}
}
@article{McCallum1998,
author = {McCallum, Andrew and Nigam, Kamal},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/McCallum, Nigam - 1998 - A Comparison of Event Models for Naive Bayes Text Classification.pdf:pdf},
journal = {AAAI-98 workshop on learning for text categorization},
number = {1},
pages = {41----48},
publisher = {Citeseer},
title = {{A Comparison of Event Models for Naive Bayes Text Classification}},
url = {https://www.semanticscholar.org/paper/A-Comparison-of-Event-Models-for-Naive-Bayes-Text-McCallum-Nigam/04ce064505b1635583fa0d9cc07cac7e9ea993cc},
volume = {752},
year = {1998}
}
@article{Wei2011,
author = {Wei, Qikang and Chen, Tao and Xu, Ruifeng and He, Yulan and Gui, Lin},
doi = {10.1093/database/baw140},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Wei et al. - 2011 - Disease named entity recognition by combining conditional random fields and bidirectional recurrent neural networks.pdf:pdf},
issn = {1758-0463},
journal = {Database},
month = {oct},
number = {4},
pages = {727--737},
publisher = {Oxford University Press},
title = {{Disease named entity recognition by combining conditional random fields and bidirectional recurrent neural networks}},
url = {https://academic.oup.com/database/article-lookup/doi/10.1093/database/baw140},
volume = {62},
year = {2011}
}
@article{PennTreebank,
author = {Marcus, Mitchell P. and Santorini, Beatrice and Marcinkiewicz, Mary Ann},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Marcus, Santorini, Marcinkiewicz - 1993 - Building a Large Annotated Corpus of English The Penn Treebank.pdf:pdf},
journal = {Computational Linguistics},
number = {2},
pages = {313----330},
title = {{Building a Large Annotated Corpus of English: The Penn Treebank}},
url = {https://aclanthology.info/papers/J93-2004/j93-2004},
volume = {19},
year = {1993}
}
@article{Macklovitch00,
author = {Macklovitch, Elliott and Simard, Michel},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Macklovitch, Simard - 2000 - Transsearch A free translation memory on the world wide web.ps:ps},
journal = {Second International Conference On Language Resources and Evaluation, LREC2000},
title = {{Transsearch: A free translation memory on the world wide web}},
url = {http://rali.iro.umontreal.ca/rali/sites/default/files/publis/TS3MT.pdf},
year = {2000}
}
@incollection{Krizhevsky2012,
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
booktitle = {Advances in Neural Information Processing Systems 25},
editor = {Pereira, F and Burges, C J C and Bottou, L and Weinberger, K Q},
file = {:Users/aussabbood/Downloads/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf:pdf},
pages = {1097--1105},
publisher = {Curran Associates, Inc.},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
year = {2012}
}
@article{Naili2017,
abstract = {The vector representations of words are very useful in different natural language processing tasks in order to capture the semantic meaning of words. In this context, the three known methods are: LSA, Word2Vec and GloVe. In this paper, these methods will be investigated in the field of topic segmentation for both languages Arabic and English. Moreover, Word2Vec is studied in depth by using different models and approximation algorithms. As results, we found out that LSA, Word2Vec and GloVe depend on the used language. However, Word2Vec presents the best word vector representation yet it depends on the choice of model.},
author = {Naili, Marwa and Chaibi, Anja Habacha and {Ben Ghezala}, Henda Hajjami},
doi = {10.1016/J.PROCS.2017.08.009},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Naili, Chaibi, Ben Ghezala - 2017 - Comparative study of word embedding methods in topic segmentation.pdf:pdf},
issn = {1877-0509},
journal = {Procedia Computer Science},
month = {jan},
pages = {340--349},
publisher = {Elsevier},
title = {{Comparative study of word embedding methods in topic segmentation}},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917313480},
volume = {112},
year = {2017}
}
@article{shap,
author = {{\v{S}}trumbelj, Erik and Kononenko, Igor},
doi = {10.1007/s10115-013-0679-x},
issn = {0219-1377},
journal = {Knowledge and Information Systems},
month = {dec},
number = {3},
pages = {647--665},
title = {{Explaining prediction models and individual predictions with feature contributions}},
url = {http://link.springer.com/10.1007/s10115-013-0679-x},
volume = {41},
year = {2014}
}
@inproceedings{Pennington2014,
author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Pennington, Socher, Manning - 2014 - GloVe Global Vectors for Word Representation.pdf:pdf},
pages = {1532--1543},
title = {{GloVe: Global Vectors for Word Representation}},
url = {http://www.aclweb.org/anthology/D14-1162},
year = {2014}
}
@inproceedings{Webster1992,
address = {Stroudsburg, PA, USA},
author = {Webster, Jonathan J. and Kit, Chunyu},
booktitle = {Proceedings of the 14th conference on Computational linguistics -},
doi = {10.3115/992424.992434},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Webster, Kit - 1992 - Tokenization as the initial phase in NLP(2).pdf:pdf},
pages = {1106--1110},
publisher = {Association for Computational Linguistics},
title = {{Tokenization as the initial phase in NLP}},
url = {http://portal.acm.org/citation.cfm?doid=992424.992434},
volume = {4},
year = {1992}
}
@incollection{DEMIS,
author = {Benzler, Justus and Kirchner, G{\"{o}}ran and Diercke, Michaela and Gilsdorf, Andreas},
booktitle = {Der Hygieneinspektor},
doi = {10.25646/1932},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Benzler et al. - 2014 - Das Projekt DEMIS.pdf:pdf},
publisher = {Robert Koch-Institut, Infektionsepidemiologie},
title = {{Das Projekt DEMIS}},
url = {https://edoc.rki.de/bitstream/handle/176904/2007/20teFClzrKjE.pdf?sequence=1{\&}isAllowed=y},
year = {2014}
}
@article{Grohe2017,
author = {Gr{\"{o}}he, Hermann},
doi = {10.1016/S0140-6736(17)31617-3},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Gr{\"{o}}he - 2017 - Together today for a healthy tomorrow-Germany's role in global health.pdf:pdf},
issn = {1474-547X},
journal = {Lancet (London, England)},
month = {aug},
number = {10097},
pages = {831--832},
pmid = {28684023},
publisher = {Elsevier},
title = {{Together today for a healthy tomorrow-Germany's role in global health.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/28684023},
volume = {390},
year = {2017}
}
@inproceedings{He2008,
author = {He, Haibo and Bai, Yang and {Edwardo A.}, Garcia and Li, Shutao},
booktitle = {2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)},
doi = {10.1109/IJCNN.2008.4633969},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Haibo He et al. - 2008 - ADASYN Adaptive synthetic sampling approach for imbalanced learning.pdf:pdf},
isbn = {978-1-4244-1820-6},
month = {jun},
pages = {1322--1328},
publisher = {IEEE},
title = {{ADASYN: Adaptive synthetic sampling approach for imbalanced learning}},
url = {http://ieeexplore.ieee.org/document/4633969/},
year = {2008}
}
@incollection{Mikolov2013,
author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
booktitle = {Advances in Neural Information Processing Systems 26},
editor = {Burges, C J C and Bottou, L and Welling, M and Ghahramani, Z and Weinberger, K Q},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Mikolov et al. - 2013 - Distributed Representations of Words and Phrases and their Compositionality.pdf:pdf},
pages = {3111--3119},
publisher = {Curran Associates, Inc.},
title = {{Distributed Representations of Words and Phrases and their Compositionality}},
url = {http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf},
year = {2013}
}
@misc{Kleene1951,
abstract = {To what kinds of events can a McCulloch-Pitts nerve net respond by firing a certain neuron? More generally, to what kinds of events can any finite automaton respond by assuming one of certain states? This memorandum is devoted to an elementary exposition of the problems and of results obtained on it during investigations in August 1951},
author = {Kleene, S C},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Kleene - 1951 - Representation of Events in Nerve Nets and Finite Automata.pdf:pdf},
keywords = {*AUTOMATA,*NEURAL NETS,BEHAVIOR,NERVE CELLS,RESPONSE,STIMULI},
mendeley-tags = {*AUTOMATA,*NEURAL NETS,BEHAVIOR,NERVE CELLS,RESPONSE,STIMULI},
pages = {103},
publisher = {RAND PROJECT AIR FORCE SANTA MONICA CA},
title = {{Representation of Events in Nerve Nets and Finite Automata}},
url = {https://apps.dtic.mil/docs/citations/ADA596138},
year = {1951}
}
@article{Maaten2008,
author = {van der Maaten, Laurens and Hinton, Geoffrey},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Maaten, Hinton - 2008 - Visualizing Data using t-SNE.pdf:pdf},
issn = {ISSN 1533-7928},
journal = {Journal of Machine Learning Research},
number = {Nov},
pages = {2579--2605},
title = {{Visualizing Data using t-SNE}},
url = {http://www.jmlr.org/papers/v9/vandermaaten08a.html},
volume = {9},
year = {2008}
}
@article{Boom2016,
author = {{De Boom}, Cedric and {Van Canneyt}, Steven and Demeester, Thomas and Dhoedt, Bart},
doi = {10.1016/j.patrec.2016.06.012},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/De Boom et al. - 2016 - Representation learning for very short texts using weighted word embedding aggregation.pdf:pdf},
issn = {01678655},
journal = {Pattern Recognition Letters},
keywords = {Artificial intelligence,Information storage and retrieval,Natural language processing,Representation learning,Word embeddings},
month = {sep},
number = {C},
pages = {150--156},
publisher = {Elsevier Science Inc.},
title = {{Representation learning for very short texts using weighted word embedding aggregation}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0167865516301362},
volume = {80},
year = {2016}
}
@book{Manning2008,
address = {Cambridge},
author = {Manning, Christopher D. and Raghavan, Prabhakar and Schutze, Hinrich},
doi = {10.1017/CBO9780511809071},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Manning, Raghavan, Schutze - 2008 - Introduction to Information Retrieval.pdf:pdf},
isbn = {9780511809071},
publisher = {Cambridge University Press},
title = {{Introduction to Information Retrieval}},
url = {http://ebooks.cambridge.org/ref/id/CBO9780511809071},
year = {2008}
}
@article{Wickham2014,
abstract = {A huge amount of effort is spent cleaning data to get it ready for analysis, but there has been little research on how to make data cleaning as easy and effective as possible. This paper tackles a small, but important, component of data cleaning: data tidying. Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets. This structure also makes it easier to develop tidy tools for data analysis, tools that both input and output tidy datasets. The advantages of a consistent data structure and matching tools are demonstrated with a case study free from mundane data manipulation chores.},
author = {Wickham, Hadley},
doi = {10.18637/jss.v059.i10},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Wickham - 2014 - Tidy Data.pdf:pdf},
issn = {1548-7660},
journal = {Journal of Statistical Software},
month = {sep},
number = {10},
pages = {1--23},
title = {{Tidy Data}},
url = {http://www.jstatsoft.org/v59/i10/},
volume = {59},
year = {2014}
}
@incollection{Marquez98,
author = {M{\`{a}}rquez, Llu{\'{i}}s and Rodr{\'{i}}guez, Horacio},
booktitle = {Machine Learning: ECML-98},
doi = {10.1007/BFb0026668},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/M{\`{a}}rquez, Rodr{\'{i}}guez - 1998 - Part-of-speech tagging using decision trees.pdf:pdf},
pages = {25--36},
title = {{Part-of-speech tagging using decision trees}},
url = {http://link.springer.com/10.1007/BFb0026668},
year = {1998}
}
@inproceedings{Baroni2014,
address = {Baltimore, Maryland , USA},
author = {Baroni, Marco and Dinu, Georgiana and Kruszewski, Germ{\'{a}}n},
booktitle = {Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics},
doi = {10.3115/v1/P14-1023},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Baroni, Dinu, Kruszewski - 2014 - Don't count, predict! A systematic comparison of context-counting vs. context-predicting semantic vect.pdf:pdf},
pages = {238--247},
publisher = {Association for Computational Linguistics},
title = {{Don't count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors}},
url = {http://aclweb.org/anthology/P14-1023},
volume = {1},
year = {2014}
}
@inproceedings{Yadav2018,
address = {Santa Fe, New Mexico, USA},
author = {Yadav, Vikas and Bethard, Steven},
booktitle = {Proceedings of the 27th International Conference on Computational Linguistics},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Yadav, Bethard - 2018 - A Survey on Recent Advances in Named Entity Recognition from Deep Learning models.pdf:pdf},
pages = {2145--2158},
publisher = {Association for Computational Linguistics},
title = {{A Survey on Recent Advances in Named Entity Recognition from Deep Learning models}},
url = {https://aclanthology.info/papers/C18-1182/c18-1182},
year = {2018}
}
@misc{IfSG,
author = {{Bundesminesterium der Justiz und f{\"{u}}r Verbraucherschutz}},
title = {{Gesetz zur Verh{\"{u}}tung und Bek{\"{a}}mpfung von Infektionskrankheiten beim Menschen}},
url = {https://www.gesetze-im-internet.de/ifsg/},
urldate = {2019-04-12},
year = {2001}
}
@inproceedings{Rau1991,
address = {Morristown, NJ, USA},
author = {Jacobs, Paul S. and Krupka, George R. and Rau, Lisa F.},
booktitle = {Proceedings of the workshop on Speech and Natural Language - HLT '91},
doi = {10.3115/112405.112477},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Jacobs, Krupka, Rau - 1991 - Lexico-semantic pattern matching as a companion to parsing in text understanding.pdf:pdf},
pages = {337--341},
publisher = {Association for Computational Linguistics},
title = {{Lexico-semantic pattern matching as a companion to parsing in text understanding}},
url = {http://portal.acm.org/citation.cfm?doid=112405.112477},
year = {1991}
}
@misc{EpiSurv,
author = {WHO},
booktitle = {WHO},
keywords = {Canada [country],Region of the Americas [region],bacterial meningitis,clean water,crises,disease control,disease outbreaks [subject],emergencies [subject],emergency preparedness,epidemics,greywater,menincoccal meningitis,meningitis [subject],meningococcal,outbreak,outbreaks,pandemic,safe water,viral meningitis,wastewater,water [subject]},
publisher = {World Health Organization},
title = {{Epidemic intelligence - systematic event detection}},
url = {https://www.who.int/csr/alertresponse/epidemicintelligence/en/},
urldate = {2019-03-11},
year = {2015}
}
@inproceedings{Johnson2016,
address = {New York, USA},
author = {Johnson, Rie and Zhang, Tong},
booktitle = {Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48},
pages = {526--534},
publisher = {JMLR.org},
title = {{Supervised and semi-supervised text categorization using LSTM for region embeddings}},
url = {https://dl.acm.org/citation.cfm?id=3045447},
year = {2016}
}
@incollection{Faensen2006,
author = {Faensen, Daniel and Claus, Hermann and Benzler, Justus and Ammon, Andrea and Pfoch, Thomas and Breuer, T and Krause, G{\'{e}}rard},
booktitle = {EuroSurveillance},
doi = {http://dx.doi.org/10.25646/602},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Faensen et al. - 2006 - SurvNet@RKI - A multistate electronic reporting system for communicable diseases.pdf:pdf},
publisher = {Robert Koch-Institut},
title = {{SurvNet@RKI - A multistate electronic reporting system for communicable diseases}},
year = {2006}
}
@article{Balakrishnan2014,
abstract = {The current study proposes to compare document retrieval precision performances based on language modeling techniques, particularly stemming and lemmatization. Stemming is a procedure to reduce all words with the same stem to a common form whereas lemmatization removes inflectional endings and returns the base or dictionary form of a word. Comparisons were also made between these two techniques with a baseline ranking algorithm (i.e. with no language processing). A search engine was developed and the algorithms were tested based on a test collection. Both mean average precisions and histograms indicate stemming and lemmatization to outperform the baseline algorithm. As for the language modeling techniques, lemmatization produced better precision compared to stemming, however the differences are insignificant. Overall the findings suggest that language modeling techniques improves document retrieval, with lemmatization technique producing the best result.},
author = {Balakrishnan, V. and Lloyd-Yemoh, E.},
doi = {10.7763/LNSE.2014.V2.134},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Balakrishnan, Lloyd-Yemoh - 2014 - Stemming and lemmatization A comparison of retrieval performances.pdf:pdf},
journal = {Lecture Notes on Software Engineering},
keywords = {T Technology (General)},
pages = {262--267},
title = {{Stemming and lemmatization: A comparison of retrieval performances}},
url = {http://eprints.um.edu.my/13423/},
year = {2014}
}
@misc{rki_definition,
author = {{Robert Koch Institute}},
title = {{RKI - Institut}},
url = {https://www.rki.de/DE/Content/Institut/institut{\_}node.html},
urldate = {2019-04-11},
year = {2018}
}
@article{EarlyDetection,
author = {WHO},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/WHO - 2014 - Early detection, assessment and response to acute public health events.pdf:pdf},
journal = {WHO},
keywords = {Publication [doctype],ihr,international health regulations [subject],surveillance [subject]},
publisher = {World Health Organization},
title = {{Early detection, assessment and response to acute public health events}},
url = {https://apps.who.int/iris/handle/10665/112667},
year = {2014}
}
@article{Bar-Hillel1960,
abstract = {Machine translation (MT) has become a multimillion dollar affair. Fully automatic, high quality translation is not a reasonable goal, not even for scientific texts. This chapter surveys the situations where translation involved has to be of high quality. A human translator, in order to arrive at his/her high quality output, is obliged to make intelligent use of extra linguistic knowledge that sometimes has to be of considerable breadth and depth. Reasonable goals are either fully automatic, low quality translation or partly automatic, or high quality translation. Full automation of the translation process is incompatible with high quality. The two possible directions where a compromise could be struck are sacrificing quality or reducing the self-sufficiency of the machine output. There are many situations where less than high quality machine output is satisfactory. However, when the aim of MT is lowered to that of high quality translation by a machine-post-editor partnership, the decisive problem becomes to determine the region of optimality in the continuum of possible divisions of labor. The exact position of this region will be a function of the state of linguistic analysis where the languages involved are submitted. With machine-time/efficiency becoming cheaper and human time becoming more expensive, continuous efforts will be made to push this region in the direction of reducing the human element. However, there is no good reason to assume that this region can be pushed to the end of the line, certainly not in the near future.},
author = {Bar-Hillel, Yehoshua},
doi = {10.1016/S0065-2458(08)60607-5},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Bar-Hillel - 1960 - The Present Status of Automatic Translation of Languages.pdf:pdf},
isbn = {9780120121014},
issn = {0065-2458},
journal = {Advances in Computers},
month = {jan},
pages = {91--163},
publisher = {Elsevier},
title = {{The Present Status of Automatic Translation of Languages}},
url = {https://www.sciencedirect.com/science/article/pii/S0065245808606075},
volume = {1},
year = {1960}
}
@article{Luhn1960,
author = {Luhn, H. P.},
doi = {10.1002/asi.5090110403},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Luhn - 1960 - Key word-in-context index for technical literature (kwic index).pdf:pdf},
issn = {0096946X},
journal = {American Documentation},
month = {oct},
number = {4},
pages = {288--295},
title = {{Key word-in-context index for technical literature (kwic index)}},
url = {http://doi.wiley.com/10.1002/asi.5090110403},
volume = {11},
year = {1960}
}
@article{Bar-Hillel1953,
author = {Bar-Hillel, Yehoshua},
doi = {10.1086/287266},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Bar-Hillel - 1953 - Some Linguistic Problems Connected with Machine Translation.pdf:pdf},
issn = {0031-8248},
journal = {Philosophy of Science},
month = {jul},
number = {3},
pages = {217--225},
publisher = {Williams and Wilkins Co.},
title = {{Some Linguistic Problems Connected with Machine Translation}},
url = {https://www.journals.uchicago.edu/doi/10.1086/287266},
volume = {20},
year = {1953}
}
@article{Levenshtein1966,
author = {{Levenshtein, Vladimir}, Iosifovich},
journal = {Soviet Physics Doklady},
pages = {707},
title = {{Binary Codes Capable of Correcting Deletions, Insertions and Reversals}},
volume = {10},
year = {1966}
}
@article{Arras2017,
abstract = {Text documents can be described by a number of abstract concepts such as semantic category, writing style, or sentiment. Machine learning (ML) models have been trained to automatically map documents to these abstract concepts, allowing to annotate very large text collections, more than could be processed by a human in a lifetime. Besides predicting the text's category very accurately, it is also highly desirable to understand how and why the categorization process takes place. In this paper, we demonstrate that such understanding can be achieved by tracing the classification decision back to individual words using layer-wise relevance propagation (LRP), a recently developed technique for explaining predictions of complex non-linear classifiers. We train two word-based ML models, a convolutional neural network (CNN) and a bag-of-words SVM classifier, on a topic categorization task and adapt the LRP method to decompose the predictions of these models onto words. Resulting scores indicate how much individual words contribute to the overall classification decision. This enables one to distill relevant information from text documents without an explicit semantic information extraction step. We further use the word-wise relevance scores for generating novel vector-based document representations which capture semantic information. Based on these document vectors, we introduce a measure of model explanatory power and show that, although the SVM and CNN models perform similarly in terms of classification accuracy, the latter exhibits a higher level of explainability which makes it more comprehensible for humans and potentially more useful for other applications.},
author = {Arras, Leila and Horn, Franziska and Montavon, Gr{\'{e}}goire and M{\"{u}}ller, Klaus-Robert and Samek, Wojciech},
doi = {10.1371/journal.pone.0181142},
editor = {Sidorov, Grigori},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Arras et al. - 2017 - {\&}quotWhat is relevant in a text document{\&}quot An interpretable machine learning approach.pdf:pdf},
issn = {1932-6203},
journal = {PLOS ONE},
month = {aug},
number = {8},
pages = {1--23},
publisher = {Public Library of Science},
title = {{"What is relevant in a text document?": An interpretable machine learning approach}},
url = {https://dx.plos.org/10.1371/journal.pone.0181142},
volume = {12},
year = {2017}
}
@article{Pedregosa2011,
author = {Pedregosa, Fabian and Varoquaux, Ga{\"{e}}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, {\'{E}}douard},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Pedregosa et al. - 2011 - Scikit-learn Machine Learning in Python.pdf:pdf},
issn = {ISSN 1533-7928},
journal = {Journal of Machine Learning Research},
number = {Oct},
pages = {2825--2830},
title = {{Scikit-learn: Machine Learning in Python}},
url = {http://www.jmlr.org/papers/v12/pedregosa11a},
volume = {12},
year = {2011}
}
@misc{RANKS2019,
author = {RANKS},
title = {{Stopwords}},
url = {https://www.ranks.nl/stopwords},
urldate = {2019-03-28},
year = {2019}
}
@article{Tong2001,
author = {Tong, Simon and Koller, Daphne},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Tong, Koller - 2001 - Support Vector Machine Active Learning with Applications to Text Classification.pdf:pdf},
issn = {ISSN 1533-7928},
journal = {Journal of Machine Learning Research},
number = {Nov},
pages = {45--66},
title = {{Support Vector Machine Active Learning with Applications to Text Classification}},
url = {http://www.jmlr.org/papers/v2/tong01a.html},
volume = {2},
year = {2001}
}
@inproceedings{lime,
author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
booktitle = {Proceedings of the 22nd {\{}ACM{\}} {\{}SIGKDD{\}} International Conference on Knowledge Discovery and Data Mining, San Francisco, CA, USA, August 13-17, 2016},
pages = {1135--1144},
title = {{"Why Should {\{}I{\}} Trust You?": Explaining the Predictions of Any Classifier}},
year = {2016}
}
@inproceedings{Lau2016,
address = {Berlin, Germany},
author = {Lau, Jey Han and Baldwin, Timothy},
booktitle = {Proceedings of the 1st Workshop on Representation Learning for NLP},
doi = {10.18653/v1/W16-1609},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Lau, Baldwin - 2016 - An Empirical Evaluation of doc2vec with Practical Insights into Document Embedding Generation.pdf:pdf},
pages = {78--86},
publisher = {Association for Computational Linguistics},
title = {{An Empirical Evaluation of doc2vec with Practical Insights into Document Embedding Generation}},
url = {http://aclweb.org/anthology/W16-1609},
year = {2016}
}
@inproceedings{Andrew2015,
author = {Dai, Andrew M and Olah, Christopher and Le, Quoc V},
booktitle = {NIPS Deep Learning Workshop},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Dai, Olah, Le - 2015 - Document embedding with paragraph vectors.pdf:pdf},
title = {{Document embedding with paragraph vectors}},
year = {2015}
}
@inproceedings{Ling2008,
author = {Ling, Charles X and Sheng, Victor S},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Ling, Sheng - 2008 - Cost-Sensitive Learning and the Class Imbalance Problem.pdf:pdf},
title = {{Cost-Sensitive Learning and the Class Imbalance Problem}},
year = {2008}
}
@article{Nadeau2009,
abstract = {This survey covers fifteen years of research in the Named Entity Recognition and Classification (NERC) field, from 1991 to 2006. We report observations about languages, named entity types, domains and textual genres studied in the literature. From the start, NERC systems have been developed using hand-made rules, but now machine learning techniques are widely used. These techniques are surveyed along with other critical aspects of NERC such as features and evaluation methods. Features are word-level, dictionary-level and corpus-level representations of words in a document. Evaluation techniques, ranging from intuitive exact match to very complex matching techniques with adjustable cost of errors, are an indisputable key to progress.},
archivePrefix = {arXiv},
arxivId = {1309.4408},
author = {Nadeau, David and Sekine, Satoshi},
doi = {10.1075/li.30.1.03nad},
eprint = {1309.4408},
file = {:Users/aussabbood/Library/Application Support/Mendeley Desktop/Downloaded/Nadeau, Sekine - 2009 - A survey of named entity recognition and classification.pdf:pdf},
isbn = {0378-4169},
issn = {0378-4169},
journal = {Lingvistic{\ae} Investigationes},
month = {aug},
number = {1},
pages = {3--26},
pmid = {1750393},
publisher = {John Benjamins},
title = {{A survey of named entity recognition and classification}},
url = {https://benjamins.com/catalog/li.30.1.03nad},
volume = {30},
year = {2009}
}
